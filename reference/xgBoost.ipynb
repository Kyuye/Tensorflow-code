{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XgBoost 분석 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. XgBoost 정의 \n",
    "\n",
    "<p><img src=\"http://www.kdnuggets.com/wp-content/uploads/xgboost-tianqi-chen.jpg\" alt=\"출처\"></p>\n",
    "##### 출처 : https://machinelearningmastery.com/gentle-introduction-xgboost-applied-machine-learning/\n",
    "\n",
    ">**XGBoost 의 의미 : eXtreme Gradient Boosting**\n",
    "\n",
    ">**Gradient boosting의 일종**\n",
    "\n",
    ">**주요기능 : Execution Speed 증가 그리고 Model Performance 향상 **\n",
    "\n",
    ">**두 가지 종류 : XGBClassifier and XGBRegressor classes in the XGBoost Python scikit-learn API **\n",
    "\n",
    "---\n",
    "\n",
    "### 2. XgBoost 의 작동방식 \n",
    "\n",
    "- Gradient Boosting algorithm : also called gradient boosting machine including the learning rate.\n",
    "- Stochastic Gradient Boosting : sub-sampling at the row, column and column per split levels.\n",
    "- Regularized Gradient Boosting : both L1 and L2 regularization.<p>\n",
    "\n",
    "---\n",
    "\n",
    "### 3. XgBoost 적용 \n",
    "\n",
    "XGBoost library는 gradient boosting decision tree 알고리즘에 적용 가능\n",
    "Regreesion or Classification 에 모두 적용 가능\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XgBoost 예시코드 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고링크 : <p> 공식홈페이지 : http://xgboost.readthedocs.io/en/latest/python/python_intro.html <p>\n",
    "parameter tuning :https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First XGBoost model for Pima Indians dataset\n",
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "# load data\n",
    "dataset = loadtxt('pima-indians-diabetes.csv', delimiter=\",\")\n",
    "# split data into X and y\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "# split data into train and test sets\n",
    "seed = 7\n",
    "test_size = 0.33\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "# fit model no training data\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 실제 적용해본 간단한 예제코드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "X = [i for i in range(10)]\n",
    "Y = [9-j for j in range(10)]\n",
    "data = np.array([X if r%2 == 0 else Y for r in range(100)],np.float32)\n",
    "label=np.array([1 if r%2 == 0 else 0 for r in range(100)],np.float32)\n",
    "\n",
    "seed = 7\n",
    "test_size = 0.33\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(x_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Influenza dataset을 활용한 실전 분석 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 필요한 파일 라이브러리 import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import utils \n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn import utils \n",
    "import numpy as np\n",
    "import operator as op \n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.datalab.bigquery as bq\n",
    "import numpy as np\n",
    "import operator as op \n",
    "import pandas as pd\n",
    "import os\n",
    "import apache_beam as beam\n",
    "import datetime\n",
    "# import tensorflow as tf \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. BigQuery로 전처리가 완료된 dataset을 qeury로 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### xgboost는 logic level로 분석하기 때문에, 사칙연산을 위한 one-hot vector로 변환하지않고 integer array dataset을 바로 적용함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "#standard\n",
    "select \n",
    "replace(replace(replace(replace(replace(replace(replace(replace(replace(replace(replace(\n",
    "host_species,\n",
    "\"IRD:Chicken/Avian\", \"1\"),\n",
    "\"IRD:Duck/Avian\", \"2\"),\n",
    "\"IRD:Mallard/Avian\", \"3\"),\n",
    "\"IRD:Environment\", \"4\"),\n",
    "\"IRD:Goose/Avian\", \"5\"),\n",
    "\"IRD:Muscovy Duck/Avian\", \"6\"),\n",
    "\"IRD:Human\", \"7\"),\n",
    "\"IRD:Turkey/Avian\", \"8\" ),\n",
    "\"IRD:Openbill Stork/Avian\", \"9\"),\n",
    "\"IRD:Baikal Teal/Avian\", \"10\"),\n",
    "\"IRD:Swine\", \"11\") as label,\n",
    "replace(replace(replace(replace(regexp_replace(\n",
    "   rpad(sequence, 2429, \"P\"),\n",
    "   \"[^ATGC]\", \",0\"),\n",
    "   \"A\", \",1\"),\n",
    "   \"T\", \",2\"),\n",
    "   \"G\", \",3\"),\n",
    "   \"C\", \",4\") as train\n",
    "from genome.influenza_sequence\n",
    "where host_species = \"IRD:Chicken/Avian\" \n",
    "or host_species = \"IRD:Duck/Avian\" \n",
    "or host_species = \"IRD:Mallard/Avian\"\n",
    "or host_species = \"IRD:Environment\"\n",
    "or host_species = \"IRD:Goose/Avian\" \n",
    "or host_species = \"IRD:Muscovy Duck/Avian\" \n",
    "or host_species = \"IRD:Human\" \n",
    "or host_species = \"IRD:Turkey/Avian\" \n",
    "or host_species = \"IRD:Openbill Stork/Avian\" \n",
    "or host_species = \"IRD:Baikal Teal/Avian\" \n",
    "or host_species = \"IRD:Swine\" \n",
    "\"\"\"\n",
    "\n",
    "# df = bq.Query(query).execute().result().to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "job_name = 'preprocess-babyweight-features' + '-' + datetime.datetime.now().strftime('%y%m%d-%H%M%S')\n",
    "OUTPUT_DIR = './preprocessed_dataset/'\n",
    "PROJECT = 'tensorflowprojects'\n",
    "options = {\n",
    "    'staging_location': os.path.join(OUTPUT_DIR, 'tmp', 'staging'),\n",
    "    'temp_location': os.path.join(OUTPUT_DIR, 'tmp'),\n",
    "    'job_name': job_name,\n",
    "    'project': PROJECT,\n",
    "    'teardown_policy': 'TEARDOWN_ALWAYS',\n",
    "    'no_save_main_session': True\n",
    "  }\n",
    "\n",
    "opts = beam.pipeline.PipelineOptions(flags=[], **options)\n",
    "RUNNER = 'DirectRunner'\n",
    "p = beam.Pipeline(RUNNER, options=opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_csv(rowdict):\n",
    "    dataset = str(rowdict['label']) + rowdict['train']\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PCollection[proc_data/WriteToText/Write/WriteImpl/finalize_write.None] at 0x7f8d59962a90>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = \"species, \" + \", \".join([\"seq_\"+str(i) for i in range(2429)])\n",
    "(p |'read_data' >> beam.io.Read(beam.io.BigQuerySource(query=query, use_standard_sql=True))\n",
    " | 'preprocessing' >> beam.Map(to_csv)\n",
    " | 'proc_data' >> beam.io.Write(beam.io.WriteToText(os.path.join(OUTPUT_DIR, '10_species'), file_name_suffix='.csv', header=cols)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = p.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### csv 파일로 저장된 데이터셋 불러와서 사용가능한 label, train 데이터셋으로 만들기 \n",
    "* Train(input) : Virus RNA Sequence , Label : host_species (11종, swine 까지)\n",
    "* 데이터 셔플링 및 training dataset : 10029개, test dataset : 4936개 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Dataset does not exist so we will create it\n"
     ]
    }
   ],
   "source": [
    "\n",
    "path = \"./preprocessed_dataset/\"\n",
    "filenames = [os.path.join(path, filename) for filename in os.listdir(path)]\n",
    "\n",
    "\n",
    "data = [pd.read_csv(f) for f in filenames]\n",
    "whole_data = pd.concat(data,axis=0)\n",
    "\n",
    "label = np.array(whole_data[\"species\"])\n",
    "train = np.array(whole_data.drop(\"species\", axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# dataset suffling \n",
    "train,label = utils.shuffle(train,label, random_state=0)\n",
    "\n",
    "\n",
    "seed = 7\n",
    "test_size = 0.33\n",
    "train_data, test_data, train_label, test_label = train_test_split(train, label, test_size=test_size, random_state=seed)\n",
    "\n",
    "\n",
    "print(\"Training_data :\",train_data.shape)\n",
    "print(\"Training_label :\",train_label.shape)\n",
    "\n",
    "print(\"Test_data :\",test_data.shape)\n",
    "print(\"Test_label :\",test_label.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. xgboost 모델 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### xgboost 모델을 적용하여 '분류' 정확도 도출 : DNA sequence 에 따라 host_species 11종 분류 정확도 (accuracy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(train_data, train_label)\n",
    "\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(test_data)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(test_label, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결과출력 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training_data : (10020, 2429) <p>\n",
    "Training_label : (10020,) <p>\n",
    "Test_data : (4936, 2429) <P>\n",
    "Test_label : (4936,)<p>\n",
    "Accuracy: 53.81%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
